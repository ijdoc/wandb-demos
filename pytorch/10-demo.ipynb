{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc78ae97-36c7-4faa-b5ab-f80bd2f10039",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ijdoc/wandb-demos/blob/main/pytorch/10-demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e7d2e8-a1b8-44e8-b4bc-9e5dcf7238d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pytorch Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f2d2d9-f04d-4264-b1c6-3137ca029121",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3836b7-4db0-402e-b52e-6c9b4e6aee4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb9242-4e21-42c3-b027-139e039a6469",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Basic Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb9c09-4efc-4bf8-ad70-4105e4fa0928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Import the W&B Python SDK\n",
    "import wandb\n",
    "\n",
    "config = {\n",
    "    \"epochs\": 10,\n",
    "    \"learning_rate\": 0.00003,\n",
    "    \"img_size\": 128,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "device, datasets, loaders, model, loss_fn, optimizer = init_training(config)\n",
    "\n",
    "# 2. Initialize logging\n",
    "wandb.init(config=config, job_type=\"train\")\n",
    "\n",
    "for epoch in range(config[\"epochs\"]):\n",
    "    loss = train_step(model, loaders[\"train\"], loss_fn, optimizer, device)\n",
    "    val_loss, accuracy = eval_step(model, loaders[\"val\"], loss_fn, device)\n",
    "\n",
    "    print(\n",
    "        f'Epoch {epoch+1}/{config[\"epochs\"]}, '\n",
    "        f\"Training Loss: {loss:.4f}, \"\n",
    "        f\"Validation Loss: {val_loss:.4f}, \"\n",
    "        f\"Accuracy: {accuracy:.4f}\"\n",
    "    )\n",
    "\n",
    "    # 3. Log metrics\n",
    "    wandb.log({\"train/loss\": loss, \"val/loss\": val_loss, \"val/acc\": accuracy})\n",
    "\n",
    "# 4. Done!!\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f5aa7-c1c7-4bff-901d-7a2b4707a56c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Log Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95097b7d-f10e-4c7b-ab05-8aaf2b3f2747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "config = {\n",
    "    \"epochs\": 10,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"img_size\": 128,\n",
    "    \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "device, datasets, loaders, model, loss_fn, optimizer = init_training(config)\n",
    "\n",
    "wandb.init(config=config, job_type=\"train\")\n",
    "\n",
    "# 4. Reference the dataset used\n",
    "wandb.use_artifact(\"team-jdoc/datasets/playing-cards:v0\", type=\"dataset\")\n",
    "\n",
    "for epoch in range(config[\"epochs\"]):\n",
    "    loss = train_step(model, loaders[\"train\"], loss_fn, optimizer, device)\n",
    "    val_loss, accuracy = eval_step(model, loaders[\"val\"], loss_fn, device)\n",
    "\n",
    "    wandb.log({\"train/loss\": loss, \"val/loss\": val_loss, \"val/acc\": accuracy})\n",
    "\n",
    "# 5. Log the resulting model\n",
    "model_path = save_model_checkpoint(model, optimizer, epoch, loss)\n",
    "model_artifact = wandb.log_artifact(model_path, type=\"model\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d956bc7-10f6-4d06-b6b5-f016a24c7bf2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Expand Lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78947223-1004-49e3-9aad-02c63d1812eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(job_type=\"test\")\n",
    "wandb.use_artifact(model_artifact)\n",
    "\n",
    "(loss, accuracy, misses) = test(\n",
    "    config[\"img_size\"],\n",
    "    model,\n",
    "    datasets[\"test\"].classes,\n",
    "    loaders[\"test\"],\n",
    "    loss_fn,\n",
    "    device,\n",
    ")\n",
    "\n",
    "wandb.log({\"test/loss\": loss, \"test/acc\": accuracy, \"test/misses\": len(misses)})\n",
    "\n",
    "# 6. Log a Table\n",
    "wandb.log({\"misses\": wandb.Table(dataframe=misses)})\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe425e2d-5631-4225-8655-f39d205b0902",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701275dd-58de-481d-b550-3bbf8c25f891",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00570fea-4c11-4cb9-9102-ae3ea83873d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ltt install torch\n",
    "!pip install timm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm  # Where the model is stored\n",
    "\n",
    "import matplotlib.pyplot as plt  # For data viz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "print(\"System Version:\", sys.version)\n",
    "print(\"PyTorch version\", torch.__version__)\n",
    "print(\"Torchvision version\", torchvision.__version__)\n",
    "print(\"Numpy version\", np.__version__)\n",
    "print(\"Pandas version\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4813613-9eeb-441b-8836-933c48dbdaae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c6c6c-474b-4496-adac-45debf6fefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_folder = \"./artifacts/playing-cards:v0/train/\"\n",
    "valid_folder = \"./artifacts/playing-cards:v0/valid/\"\n",
    "test_folder = \"./artifacts/playing-cards:v0/test/\"\n",
    "\n",
    "\n",
    "class ImageFolderWithPaths(ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends torchvision.datasets.ImageFolder\"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method that dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns\n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = original_tuple + (path,)\n",
    "        return tuple_with_path\n",
    "\n",
    "\n",
    "def get_transform(img_size):\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def prep_data(img_size, batch_size):\n",
    "    transform = get_transform(img_size)\n",
    "    # Load datasets as tensors\n",
    "\n",
    "    train_dataset = ImageFolderWithPaths(train_folder, transform=transform)\n",
    "    val_dataset = ImageFolderWithPaths(valid_folder, transform=transform)\n",
    "    test_dataset = ImageFolderWithPaths(test_folder, transform=transform)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return {\n",
    "        \"sets\": {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset},\n",
    "        \"loaders\": {\n",
    "            \"train\": train_dataloader,\n",
    "            \"val\": val_dataloader,\n",
    "            \"test\": test_dataloader,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def show_sample(dataset):\n",
    "    image, label, path = random.choice(dataset)\n",
    "    plt.imshow(Image.open(path))\n",
    "    plt.axis(\"off\")  # Hide the axis\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_sample(prep_data(128, 128)[\"sets\"][\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b731e6fe-8f0e-4085-89d2-e0329749ccc0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9108adf-2e1e-4dc3-af12-c24a418235d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=53):\n",
    "        super(CardClassifier, self).__init__()\n",
    "\n",
    "        # Define base model\n",
    "        self.base_model = timm.create_model(\"efficientnet_b0\", pretrained=True)\n",
    "\n",
    "        # Remove last layer\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "        # Keep a reference to the removed layer so we know how many connections\n",
    "        # we need for the new last layer\n",
    "        removed_layer = list(self.base_model.children())[-1]\n",
    "\n",
    "        # Recreate the last layer (the classifier)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(), nn.Linear(removed_layer.in_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Connect these parts and return the output\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "# model = CardClassifier(num_classes)\n",
    "# predictions = model(images)\n",
    "# predictions.shape  # [batch_size, num_classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d48f3ef-7b42-4940-9437-4236bb59748d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a6ce0-fe94-4dce-8410-327f1377f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def init_training(config):\n",
    "    # Device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training on {device}\")\n",
    "\n",
    "    # Data\n",
    "    data_objects = prep_data(config[\"img_size\"], config[\"batch_size\"])\n",
    "    datasets = data_objects[\"sets\"]\n",
    "    loaders = data_objects[\"loaders\"]\n",
    "\n",
    "    # Model\n",
    "    model = CardClassifier()\n",
    "    model = model.to(device)\n",
    "    # Loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "    return device, datasets, loaders, model, loss_fn, optimizer\n",
    "\n",
    "\n",
    "def train_step(model, dataloader, loss_fn, optimizer, device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for X_batch, y_batch, _ in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(\n",
    "            device\n",
    "        )  # Move data to the appropriate device (CPU/GPU)\n",
    "\n",
    "        optimizer.zero_grad()  # Reset gradients to zero to avoid accumulation\n",
    "\n",
    "        y_pred = model(X_batch)  # Forward pass: compute the model output\n",
    "        loss = loss_fn(y_pred, y_batch)  # Compute the loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()  # Backward pass: compute the gradient of the loss with respect to model parameters\n",
    "        optimizer.step()  # Update parameters\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    return average_loss  # Return the average loss for the epoch\n",
    "\n",
    "\n",
    "def eval_step(model, dataloader, loss_fn, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    with torch.no_grad():  # No gradients needed for validation, saves memory and computations\n",
    "        for X_batch, y_batch, _ in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Assuming y_pred are raw logits, you could adapt this depending on your output\n",
    "            predicted = torch.argmax(y_pred, dim=1)\n",
    "            total_correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    accuracy = total_correct / len(dataloader.dataset)\n",
    "\n",
    "    return (\n",
    "        average_loss,\n",
    "        accuracy,\n",
    "    )  # Return the average loss and accuracy\n",
    "\n",
    "\n",
    "def test(img_size, model, class_names, dataloader, loss_fn, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "        ]\n",
    "    )\n",
    "    # Create an empty DataFrame\n",
    "    misses = pd.DataFrame(columns=[\"image\", \"truth\", \"guess\"])\n",
    "\n",
    "    with torch.no_grad():  # No gradients needed, saves memory and computations\n",
    "        for X_batch, y_batch, image_paths in dataloader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Convert outputs probabilities to predicted class\n",
    "            _, preds = torch.max(y_pred, 1)\n",
    "            total_correct += (preds == y_batch).sum().item()\n",
    "            missed_idxs = torch.where(preds != y_batch)[0]\n",
    "            # Append misclassified samples to the DataFrame\n",
    "            for idx in missed_idxs:\n",
    "                misses.loc[len(misses)] = {\n",
    "                    \"image\": wandb.Image(transform(Image.open(image_paths[idx]))),\n",
    "                    \"truth\": class_names[y_batch[idx]],\n",
    "                    \"guess\": class_names[preds[idx]],\n",
    "                }\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    accuracy = total_correct / len(dataloader.dataset)\n",
    "\n",
    "    # Return the average loss, accuracy and misclassifications\n",
    "    return (\n",
    "        average_loss,\n",
    "        accuracy,\n",
    "        misses,\n",
    "    )\n",
    "\n",
    "\n",
    "def save_model_checkpoint(model, optimizer, epoch, loss):\n",
    "    # Save the model state and the optimizer state\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"loss\": loss,\n",
    "        # You can add more items to the checkpoint if needed\n",
    "    }\n",
    "\n",
    "    # Specify the directory you want to create\n",
    "    checkpoints_dir = \"./checkpoints\"\n",
    "\n",
    "    # Check whether the specified path exists or not\n",
    "    if not os.path.exists(checkpoints_dir):\n",
    "        os.makedirs(checkpoints_dir)  # Create a new directory because it does not exist\n",
    "    filepath = f\"{checkpoints_dir}/{epoch}_card_classifier_checkpoint.pth\"\n",
    "\n",
    "    # Save to file\n",
    "    torch.save(checkpoint, filepath)\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ab1ce-c41f-4475-a392-de0708366dd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facea79a-1c5d-4c42-b83e-d5e7da6bcad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip show wandb\n",
    "import wandb\n",
    "\n",
    "dir(wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56762c-6060-4342-ab8b-4445d735e47c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d70e6-7d5d-43b9-8ee6-ce942115e1e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(misses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
