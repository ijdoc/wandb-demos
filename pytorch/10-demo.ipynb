{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc78ae97-36c7-4faa-b5ab-f80bd2f10039",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ijdoc/wandb-demos/blob/main/pytorch/10-demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe425e2d-5631-4225-8655-f39d205b0902",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701275dd-58de-481d-b550-3bbf8c25f891",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00570fea-4c11-4cb9-9102-ae3ea83873d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ltt install torch\n",
    "!pip install timm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm # Where the model is stored\n",
    "\n",
    "import matplotlib.pyplot as plt # For data viz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print('System Version:', sys.version)\n",
    "print('PyTorch version', torch.__version__)\n",
    "print('Torchvision version', torchvision.__version__)\n",
    "print('Numpy version', np.__version__)\n",
    "print('Pandas version', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4813613-9eeb-441b-8836-933c48dbdaae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prepare Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c6c6c-474b-4496-adac-45debf6fefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class PlayingCardsDataset(Dataset):\n",
    "  def __init__(self, data_dir, transform=None):\n",
    "    self.data = ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      return self.data[idx]\n",
    "\n",
    "  @property\n",
    "  def classes(self):\n",
    "    return self.data.classes\n",
    "\n",
    "def get_dataloaders(img_size, batch_size):\n",
    "  convert = transforms.Compose([\n",
    "      transforms.Resize((img_size, img_size)),\n",
    "      transforms.ToTensor(),\n",
    "  ])\n",
    "  # Load datasets as tensors\n",
    "  train_folder = './artifacts/playing-cards:v0/train/'\n",
    "  valid_folder = './artifacts/playing-cards:v0/valid/'\n",
    "  test_folder = './artifacts/playing-cards:v0/test/'\n",
    "\n",
    "  train_dataset = PlayingCardsDataset(train_folder, transform=convert)\n",
    "  val_dataset = PlayingCardsDataset(valid_folder, transform=convert)\n",
    "  test_dataset = PlayingCardsDataset(test_folder, transform=convert)\n",
    "\n",
    "  train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "  val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "  test_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "  return {\"train\": train_dataloader, \"val\": val_dataloader, \"test\": test_dataloader}\n",
    "\n",
    "def show_sample(img_size):\n",
    "  resize = transforms.Compose([\n",
    "      transforms.Resize((img_size, img_size)),\n",
    "  ])\n",
    "  dataset = PlayingCardsDataset(\"./artifacts/playing-cards:v0/train\", transform=resize)\n",
    "  image, label = random.choice(dataset)\n",
    "  plt.imshow(image)\n",
    "  plt.axis('off')  # Hide the axis\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "show_sample(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b731e6fe-8f0e-4085-89d2-e0329749ccc0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9108adf-2e1e-4dc3-af12-c24a418235d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardClassifier(nn.Module):\n",
    "  def __init__(self, num_classes=53):\n",
    "    super(CardClassifier, self).__init__()\n",
    "\n",
    "    # Define base model\n",
    "    self.base_model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "\n",
    "    # Remove last layer\n",
    "    self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "    # Keep a reference to the removed layer so we know how many connections\n",
    "    # we need for the new last layer\n",
    "    removed_layer = list(self.base_model.children())[-1]\n",
    "\n",
    "    # Recreate the last layer (the classifier)\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(removed_layer.in_features, num_classes)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Connect these parts and return the output\n",
    "    x = self.features(x)\n",
    "    return self.classifier(x)\n",
    "\n",
    "# model = CardClassifier(num_classes)\n",
    "# predictions = model(images)\n",
    "# predictions.shape  # [batch_size, num_classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d48f3ef-7b42-4940-9437-4236bb59748d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a6ce0-fe94-4dce-8410-327f1377f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def init_training(config):\n",
    "  # Device\n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "  print(f'Training on {device}')\n",
    "\n",
    "  # Dataloaders\n",
    "  dataloaders = get_dataloaders(config[\"img_size\"], config[\"batch_size\"])\n",
    "\n",
    "  # Model\n",
    "  model = CardClassifier()\n",
    "  model = model.to(device)\n",
    "  # Loss function\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "  # Optimizer\n",
    "  optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "  return device, dataloaders, model, loss_fn, optimizer\n",
    "\n",
    "def train_step(model, dataloader, loss_fn, optimizer, device):\n",
    "  model.train()  # Set the model to training mode\n",
    "  total_loss = 0\n",
    "\n",
    "  for X_batch, y_batch in dataloader:\n",
    "    X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Move data to the appropriate device (CPU/GPU)\n",
    "\n",
    "    optimizer.zero_grad()  # Reset gradients to zero to avoid accumulation\n",
    "\n",
    "    y_pred = model(X_batch)  # Forward pass: compute the model output\n",
    "    loss = loss_fn(y_pred, y_batch)  # Compute the loss\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    loss.backward()  # Backward pass: compute the gradient of the loss with respect to model parameters\n",
    "    optimizer.step()  # Update parameters\n",
    "\n",
    "  average_loss = total_loss / len(dataloader)\n",
    "  return average_loss  # Return the average loss for the epoch\n",
    "\n",
    "def validate_step(model, dataloader, loss_fn, device):\n",
    "  model.eval()  # Set the model to evaluation mode\n",
    "  total_loss = 0\n",
    "  total_correct = 0\n",
    "\n",
    "  with torch.no_grad():  # No gradients needed for validation, saves memory and computations\n",
    "    for X_batch, y_batch in dataloader:\n",
    "      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "      y_pred = model(X_batch)\n",
    "      loss = loss_fn(y_pred, y_batch)\n",
    "      total_loss += loss.item()\n",
    "\n",
    "      # Assuming y_pred are raw logits, you could adapt this depending on your output\n",
    "      predicted = torch.argmax(y_pred, dim=1)\n",
    "      total_correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "  average_loss = total_loss / len(dataloader)\n",
    "  accuracy = total_correct / len(dataloader.dataset)\n",
    "\n",
    "  return average_loss, accuracy  # Return the average loss and accuracy for the validation set\n",
    "\n",
    "def save_model_checkpoint(model, optimizer, epoch, loss):\n",
    "  # Save the model state and the optimizer state\n",
    "  checkpoint = {\n",
    "      'epoch': epoch,\n",
    "      'model_state_dict': model.state_dict(),\n",
    "      'optimizer_state_dict': optimizer.state_dict(),\n",
    "      'loss': loss,\n",
    "      # You can add more items to the checkpoint if needed\n",
    "  }\n",
    "\n",
    "  # Specify the directory you want to create\n",
    "  checkpoints_dir = \"./checkpoints\"\n",
    "\n",
    "  # Check whether the specified path exists or not\n",
    "  if not os.path.exists(checkpoints_dir):\n",
    "      os.makedirs(checkpoints_dir)  # Create a new directory because it does not exist\n",
    "  filepath = f'{checkpoints_dir}/{epoch}_card_classifier_checkpoint.pth'\n",
    "\n",
    "  # Save to file\n",
    "  torch.save(checkpoint, filepath)\n",
    "\n",
    "  return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e7d2e8-a1b8-44e8-b4bc-9e5dcf7238d7",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f2d2d9-f04d-4264-b1c6-3137ca029121",
   "metadata": {},
   "source": [
    "## Install SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b7766-19f1-4539-bbf3-7b4e4fd2c75e",
   "metadata": {},
   "source": [
    "```shell\n",
    "pip install wandb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb9242-4e21-42c3-b027-139e039a6469",
   "metadata": {},
   "source": [
    "## Integrate SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb9c09-4efc-4bf8-ad70-4105e4fa0928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the W&B Python SDK\n",
    "import wandb\n",
    "\n",
    "config = {\n",
    "  \"epochs\": 5,\n",
    "  \"learning_rate\": 0.0001,\n",
    "  \"img_size\": 128,\n",
    "  \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "# 2. Initialize logging\n",
    "wandb.init(config=config, job_type=\"train\")\n",
    "\n",
    "device, dataloaders, model, loss_fn, optimizer = init_training(config)\n",
    "\n",
    "for epoch in range(config[\"epochs\"]):\n",
    "  loss = train_step(model, dataloaders[\"train\"], loss_fn, optimizer, device)\n",
    "  val_loss, accuracy = validate_step(model, dataloaders[\"val\"], loss_fn, device)\n",
    "\n",
    "  print(f'Epoch {epoch+1}/{config[\"epochs\"]}, '\n",
    "        f'Training Loss: {loss:.4f}, '\n",
    "        f'Validation Loss: {val_loss:.4f}, '\n",
    "        f'Accuracy: {accuracy:.4f}')\n",
    "  # 3. Log metrics\n",
    "  wandb.log({\"train/loss\": loss, \"val/loss\": val_loss, \"val/acc\": accuracy})\n",
    "\n",
    "# 4. Done!!\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f5aa7-c1c7-4bff-901d-7a2b4707a56c",
   "metadata": {},
   "source": [
    "## Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95097b7d-f10e-4c7b-ab05-8aaf2b3f2747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "config = {\n",
    "  \"epochs\": 5,\n",
    "  \"learning_rate\": 0.0001,\n",
    "  \"img_size\": 128,\n",
    "  \"batch_size\": 32,\n",
    "}\n",
    "\n",
    "wandb.init(config=config, job_type=\"train\")\n",
    "\n",
    "# 1. Reference the dataset used\n",
    "wandb.use_artifact('team-jdoc/datasets/playing-cards:v0', type='dataset')\n",
    "\n",
    "device, dataloaders, model, loss_fn, optimizer = init_training(config)\n",
    "\n",
    "for epoch in range(config[\"epochs\"]):\n",
    "  loss = train_step(model, dataloaders[\"train\"], loss_fn, optimizer, device)\n",
    "  val_loss, accuracy = validate_step(model, dataloaders[\"val\"], loss_fn, device)\n",
    "\n",
    "  print(f'Epoch {epoch+1}/{config[\"epochs\"]}, '\n",
    "        f'Training Loss: {loss:.4f}, '\n",
    "        f'Validation Loss: {val_loss:.4f}, '\n",
    "        f'Accuracy: {accuracy:.4f}')\n",
    "  wandb.log({\"train/loss\": loss, \"val/loss\": val_loss, \"val/acc\": accuracy})\n",
    "\n",
    "# 2. Log the resulting model\n",
    "model_path = save_model_checkpoint(model, optimizer, epoch, loss)\n",
    "model_artifact = wandb.log_artifact(model_path, type='model')\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d956bc7-10f6-4d06-b6b5-f016a24c7bf2",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78947223-1004-49e3-9aad-02c63d1812eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(job_type=\"test\")\n",
    "wandb.use_artifact(model_artifact)\n",
    "\n",
    "# Do the actual evaluation\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ab1ce-c41f-4475-a392-de0708366dd2",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56762c-6060-4342-ab8b-4445d735e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
